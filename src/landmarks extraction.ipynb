{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af9343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from math import sqrt, atan2\n",
    "\n",
    "# --- MediaPipe Solutions ---\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# --- Configuration Based on MSE-GCN Paper ---\n",
    "# The paper specifies using 65 joints in total.\n",
    "# We will select 23 pose landmarks + 21 for each hand = 65 total landmarks.\n",
    "config = {\n",
    "    \"VIDEO_SOURCE_DIR\": r\"D:\\WLASL DataSet\\WLASL FULL\\videos\",\n",
    "    \"SPLIT_FILE_PATH\": r\"D:\\WLASL DataSet\\WLASL FULL\\nslt_300.json\",\n",
    "    \"OUTPUT_NPZ_PATH\": r\"D:\\MSE-GCN paper methodology\\Landmarks\\MSE_GCN_features.npz\",\n",
    "    \"SAVE_CHECKPOINT_EVERY_N_VIDEOS\": 250,\n",
    "\n",
    "    # 23 pose landmarks to capture body and face movements as described in the paper [cite: 189]\n",
    "    \"POSE_LANDMARKS_TO_EXTRACT\": [\n",
    "        mp_holistic.PoseLandmark.NOSE, mp_holistic.PoseLandmark.LEFT_EYE_INNER,\n",
    "        mp_holistic.PoseLandmark.LEFT_EYE, mp_holistic.PoseLandmark.LEFT_EYE_OUTER,\n",
    "        mp_holistic.PoseLandmark.RIGHT_EYE_INNER, mp_holistic.PoseLandmark.RIGHT_EYE,\n",
    "        mp_holistic.PoseLandmark.RIGHT_EYE_OUTER, mp_holistic.PoseLandmark.LEFT_EAR,\n",
    "        mp_holistic.PoseLandmark.RIGHT_EAR, mp_holistic.PoseLandmark.MOUTH_LEFT,\n",
    "        mp_holistic.PoseLandmark.MOUTH_RIGHT, mp_holistic.PoseLandmark.LEFT_SHOULDER,\n",
    "        mp_holistic.PoseLandmark.RIGHT_SHOULDER, mp_holistic.PoseLandmark.LEFT_ELBOW,\n",
    "        mp_holistic.PoseLandmark.RIGHT_ELBOW, mp_holistic.PoseLandmark.LEFT_WRIST,\n",
    "        mp_holistic.PoseLandmark.RIGHT_WRIST, mp_holistic.PoseLandmark.LEFT_PINKY,\n",
    "        mp_holistic.PoseLandmark.RIGHT_PINKY, mp_holistic.PoseLandmark.LEFT_INDEX,\n",
    "        mp_holistic.PoseLandmark.RIGHT_INDEX, mp_holistic.PoseLandmark.LEFT_THUMB,\n",
    "        mp_holistic.PoseLandmark.RIGHT_THUMB\n",
    "    ],\n",
    "\n",
    "    # Define bone connections for Bone Stream features (length and angle)\n",
    "    \"BONE_CONNECTIONS\": [\n",
    "        # Arms\n",
    "        (mp_holistic.PoseLandmark.LEFT_SHOULDER, mp_holistic.PoseLandmark.LEFT_ELBOW),\n",
    "        (mp_holistic.PoseLandmark.LEFT_ELBOW, mp_holistic.PoseLandmark.LEFT_WRIST),\n",
    "        (mp_holistic.PoseLandmark.RIGHT_SHOULDER, mp_holistic.PoseLandmark.RIGHT_ELBOW),\n",
    "        (mp_holistic.PoseLandmark.RIGHT_ELBOW, mp_holistic.PoseLandmark.RIGHT_WRIST),\n",
    "        # Torso\n",
    "        (mp_holistic.PoseLandmark.LEFT_SHOULDER, mp_holistic.PoseLandmark.RIGHT_SHOULDER),\n",
    "    ]\n",
    "}\n",
    "\n",
    "def get_joint_and_bone_labels():\n",
    "    \"\"\"Generates labels for the 65 joints and defined bones.\"\"\"\n",
    "    joint_labels = [lm.name for lm in config[\"POSE_LANDMARKS_TO_EXTRACT\"]]\n",
    "    for i in range(21):\n",
    "        joint_labels.append(f\"LEFT_HAND_{i}\")\n",
    "    for i in range(21):\n",
    "        joint_labels.append(f\"RIGHT_HAND_{i}\")\n",
    "\n",
    "    bone_labels = []\n",
    "    for start_lm, end_lm in config[\"BONE_CONNECTIONS\"]:\n",
    "        bone_labels.append(f\"BONE_{start_lm.name}_TO_{end_lm.name}\")\n",
    "\n",
    "    return joint_labels, bone_labels\n",
    "\n",
    "def process_frame_for_mse_gcn(results):\n",
    "    \"\"\"\n",
    "    Processes a single frame's landmarks to generate the 'joints' and 'bones' streams\n",
    "    as per the MSE-GCN paper methodology.\n",
    "    \"\"\"\n",
    "    # --- 1. Extract all 65 raw joint coordinates (x, y) ---\n",
    "    raw_joints = np.zeros((65, 2), dtype=np.float32) # Using 2D coordinates as per paper\n",
    "    if results.pose_landmarks:\n",
    "        for i, lm_enum in enumerate(config[\"POSE_LANDMARKS_TO_EXTRACT\"]):\n",
    "            lm = results.pose_landmarks.landmark[lm_enum]\n",
    "            raw_joints[i] = [lm.x, lm.y]\n",
    "\n",
    "    if results.left_hand_landmarks:\n",
    "        for i, lm in enumerate(results.left_hand_landmarks.landmark):\n",
    "            raw_joints[23 + i] = [lm.x, lm.y]\n",
    "\n",
    "    if results.right_hand_landmarks:\n",
    "        for i, lm in enumerate(results.right_hand_landmarks.landmark):\n",
    "            raw_joints[44 + i] = [lm.x, lm.y]\n",
    "\n",
    "    # --- 2. Calculate Features for the \"Joints\" Stream ---\n",
    "    joint_features = np.zeros((65, 4), dtype=np.float32)\n",
    "    joint_features[:, :2] = raw_joints # First 2 channels are original (x, y)\n",
    "\n",
    "    # Calculate center node v_t,c (midpoint of shoulders) for relative position [cite: 241]\n",
    "    center_node = np.zeros(2)\n",
    "    if results.pose_landmarks:\n",
    "        l_sh = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER]\n",
    "        r_sh = results.pose_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER]\n",
    "        center_node = np.array([(l_sh.x + r_sh.x) / 2, (l_sh.y + r_sh.y) / 2])\n",
    "\n",
    "    # Calculate relative positions and add to the next 2 channels [cite: 238, 240]\n",
    "    # If a joint was not detected (is [0,0]), its relative position will also be zero\n",
    "    relative_positions = raw_joints - center_node\n",
    "    joint_features[:, 2:] = relative_positions\n",
    "\n",
    "    # --- 3. Calculate Features for the \"Bones\" Stream ---\n",
    "    num_bones = len(config[\"BONE_CONNECTIONS\"])\n",
    "    bone_features = np.zeros(num_bones * 2, dtype=np.float32) # length and angle for each bone\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        for i, (start_lm, end_lm) in enumerate(config[\"BONE_CONNECTIONS\"]):\n",
    "            start_pt = np.array([landmarks[start_lm].x, landmarks[start_lm].y])\n",
    "            end_pt = np.array([landmarks[end_lm].x, landmarks[end_lm].y])\n",
    "\n",
    "            # Calculate Bone Length (B_L) [cite: 244]\n",
    "            diff = end_pt - start_pt\n",
    "            length = sqrt(diff[0]**2 + diff[1]**2)\n",
    "            \n",
    "            # Calculate Bone Angle (B_A) [cite: 248]\n",
    "            # We use atan2 for a stable 2D orientation angle.\n",
    "            angle = atan2(diff[1], diff[0])\n",
    "\n",
    "            bone_features[i*2] = length\n",
    "            bone_features[i*2 + 1] = angle\n",
    "\n",
    "    return joint_features, bone_features\n",
    "\n",
    "def extract_features_from_video(video_path, holistic_model):\n",
    "    \"\"\"\n",
    "    Extracts MSE-GCN compliant joint and bone feature sequences from a video file.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Warning: Could not open video {video_path}\")\n",
    "        return None, None\n",
    "\n",
    "    joint_sequence = []\n",
    "    bone_sequence = []\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = holistic_model.process(image)\n",
    "            image.flags.writeable = True\n",
    "\n",
    "            joint_features, bone_features = process_frame_for_mse_gcn(results)\n",
    "            joint_sequence.append(joint_features)\n",
    "            bone_sequence.append(bone_features)\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    if not joint_sequence:\n",
    "        return None, None\n",
    "\n",
    "    return np.array(joint_sequence, dtype=np.float32), np.array(bone_sequence, dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb42a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features will be saved in: MSE_GCN_features_individual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 5118/5118 [20:16:29<00:00, 14.26s/it]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extraction complete. Processed 5116 new videos.\n"
     ]
    }
   ],
   "source": [
    "def main_extraction():\n",
    "    \"\"\"\n",
    "    Main function to process all videos and save their features\n",
    "    into INDIVIDUAL files to prevent memory errors.\n",
    "    \"\"\"\n",
    "    # Create a directory to store the individual feature files\n",
    "    output_dir = \"MSE_GCN_features_individual\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Features will be saved in: {output_dir}\")\n",
    "\n",
    "    with open(config[\"SPLIT_FILE_PATH\"], 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    video_ids = list(data.keys())\n",
    "    \n",
    "    holistic = mp_holistic.Holistic(static_image_mode=False,\n",
    "                                      model_complexity=1,\n",
    "                                      min_detection_confidence=0.5,\n",
    "                                      min_tracking_confidence=0.5)\n",
    "\n",
    "    processed_count = 0\n",
    "    try:\n",
    "        for vid in tqdm(video_ids, desc=\"Processing Videos\"):\n",
    "            path = os.path.join(config[\"VIDEO_SOURCE_DIR\"], f\"{vid}.mp4\")\n",
    "            output_path = os.path.join(output_dir, f\"{vid}.npz\")\n",
    "\n",
    "            # Skip if the file has already been processed\n",
    "            if os.path.exists(output_path):\n",
    "                continue\n",
    "            \n",
    "            if not os.path.exists(path):\n",
    "                continue\n",
    "            \n",
    "            # --- This is the same function from the previous script ---\n",
    "            joint_seq, bone_seq = extract_features_from_video(path, holistic)\n",
    "\n",
    "            if joint_seq is not None:\n",
    "                # Save the features for THIS video immediately\n",
    "                np.savez_compressed(\n",
    "                    output_path,\n",
    "                    joint_sequence=joint_seq,\n",
    "                    bone_sequence=bone_seq\n",
    "                )\n",
    "                processed_count += 1\n",
    "\n",
    "    finally:\n",
    "        holistic.close()\n",
    "        print(f\"\\nExtraction complete. Processed {processed_count} new videos.\")\n",
    "        # We no longer need a final save because we saved incrementally.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the extraction process\n",
    "    main_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68057593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5116 files to combine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining Files:   0%|          | 0/5116 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining Files: 100%|██████████| 5116/5116 [01:39<00:00, 51.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving combined data to D:\\MSE-GCN paper methodology\\Landmarks/MSE_GCN_combined_features.npz...\n",
      "Combining complete!\n",
      "Your final file is ready at: D:\\MSE-GCN paper methodology\\Landmarks/MSE_GCN_combined_features.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def combine_npz_files(input_dir, output_path):\n",
    "    \"\"\"\n",
    "    Combines all .npz files from an input directory into a single compressed .npz file.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): The directory containing the individual .npz files.\n",
    "        output_path (str): The path to save the final combined .npz file.\n",
    "    \"\"\"\n",
    "    all_features = {}\n",
    "    \n",
    "    # Check if the input directory exists\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"Error: Input directory not found at '{input_dir}'\")\n",
    "        return\n",
    "\n",
    "    file_list = [f for f in os.listdir(input_dir) if f.endswith('.npz')]\n",
    "    \n",
    "    if not file_list:\n",
    "        print(f\"No .npz files found in '{input_dir}'\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(file_list)} files to combine.\")\n",
    "\n",
    "    # Loop through each file, load it, and add it to the dictionary\n",
    "    for filename in tqdm(file_list, desc=\"Combining Files\"):\n",
    "        video_id = os.path.splitext(filename)[0]\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            with np.load(file_path) as data:\n",
    "                # Store the data in a nested dictionary\n",
    "                all_features[video_id] = {\n",
    "                    'joint_sequence': data['joint_sequence'],\n",
    "                    'bone_sequence': data['bone_sequence']\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process file {filename}: {e}\")\n",
    "\n",
    "    # Save the entire dictionary into a single compressed .npz file\n",
    "    print(f\"\\nSaving combined data to {output_path}...\")\n",
    "    np.savez_compressed(output_path, **all_features)\n",
    "    \n",
    "    print(\"Combining complete!\")\n",
    "    print(f\"Your final file is ready at: {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    # Directory where you saved your individual landmark files\n",
    "    INPUT_DIRECTORY = r\"D:\\MSE-GCN paper methodology\\MSE_GCN_features_individual\"\n",
    "    \n",
    "    # The name of the final, combined file\n",
    "    OUTPUT_FILE = r\"D:\\MSE-GCN paper methodology\\Landmarks/MSE_GCN_combined_features.npz\"\n",
    "\n",
    "    combine_npz_files(INPUT_DIRECTORY, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b27d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
